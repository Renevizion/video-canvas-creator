# Video Analysis Integration Guide

## ðŸŽ¥ FFmpeg-Powered Video Analysis

Your system now has **FREE, unlimited video analysis** using FFmpeg - no API keys, no signup, no costs!

## What It Does

The `analyze-video` backend extracts **real data** from videos:

âœ… **Frame Extraction** - Actual frames from MP4 files  
âœ… **Scene Detection** - Precise timestamps of transitions  
âœ… **Audio Analysis** - Volume levels, beat detection, codec info  
âœ… **Color Extraction** - Real colors from video pixels  
âœ… **Metadata** - Duration, resolution, FPS, codecs, bitrate  
âœ… **YouTube Support** - Analyzes YouTube videos via free thumbnails  

## How AI Agents Use It

### Asset Agent Integration

When a user provides a **reference video**, the Asset Agent automatically:

1. **Calls analyze-video** with the video file or URL
2. **Extracts visual patterns:**
   - Scene structure with timestamps
   - Color palette (real colors from frames)
   - Audio characteristics
   - Pacing and rhythm
3. **Creates matching video plan:**
   - Same scene count and duration
   - Matching color scheme
   - Similar pacing
   - Aligned audio style

### Example Workflow

```typescript
// User uploads a reference video
const referenceVideo = videoFile;

// Asset Agent calls analyze-video
const analysis = await analyzeVideo(referenceVideo);

// Returns:
{
  duration: 25.5,
  resolution: { width: 1920, height: 1080 },
  fps: 30,
  sceneChanges: [5.2, 12.8, 20.1],  // Scene transitions
  colors: ['#2563eb', '#1e293b', '#f59e0b'],  // Real colors!
  audio: {
    meanVolume: -18.5,  // dB
    maxVolume: -6.2,
    hasBeat: true,
    codec: 'aac'
  }
}

// Agent creates video plan matching this structure
```

## API Usage

### Frontend Upload

```typescript
// Convert video to base64
const reader = new FileReader();
reader.readAsDataURL(videoFile);
reader.onload = async () => {
  const base64 = reader.result.split(',')[1];
  
  // Call Supabase edge function
  const response = await supabase.functions.invoke('analyze-video', {
    body: {
      videoBase64: base64,
      videoName: videoFile.name,
      frameCount: 5  // Extract 5 frames for analysis
    }
  });
  
  const { pattern, metadata } = response.data;
  
  console.log('Scene changes:', pattern.sceneChanges);
  console.log('Real colors:', pattern.colors);
  console.log('Has beat:', pattern.audio.hasBeat);
};
```

### YouTube URL

```typescript
const response = await supabase.functions.invoke('analyze-video', {
  body: {
    videoUrl: 'https://www.youtube.com/watch?v=VIDEO_ID',
    frameCount: 3
  }
});

const { pattern } = response.data;
// Uses free YouTube thumbnails for analysis
```

## Tool Definition for Agents

```typescript
const analyzeVideoTool = {
  name: 'analyze-video',
  description: 'Extract real patterns from video files using FFmpeg',
  parameters: {
    input: {
      type: 'object',
      properties: {
        videoBase64: {
          type: 'string',
          description: 'Base64-encoded video file (for uploads)'
        },
        videoUrl: {
          type: 'string',
          description: 'YouTube URL (for YouTube videos)'
        },
        videoName: {
          type: 'string',
          description: 'Original filename'
        },
        frameCount: {
          type: 'number',
          description: 'Number of frames to extract (default: 5)',
          default: 5
        }
      }
    }
  },
  returns: {
    pattern: {
      colors: ['#hex1', '#hex2', ...],  // Real extracted colors
      sceneChanges: [5.2, 12.8, ...],   // Scene timestamps
      duration: 25.5,
      resolution: { width: 1920, height: 1080 },
      fps: 30,
      audio: {
        meanVolume: -18.5,
        maxVolume: -6.2,
        hasBeat: true,
        codec: 'aac'
      }
    },
    metadata: {
      processTime: 5.2,  // seconds
      frameUrls: ['frame1.jpg', 'frame2.jpg', ...]
    }
  }
};
```

## Use Cases

### 1. Style Transfer

**User:** "Make a video like this [uploads reference.mp4]"

**Process:**
1. Asset Agent calls analyze-video
2. Extracts: colors, scene timing, pacing
3. Story Agent creates plan matching the style
4. Result: New video with same visual feel

### 2. Brand Matching

**User:** "Create a promo video matching our brand video"

**Process:**
1. Analyze brand video â†’ Extract color palette
2. Brand Agent uses extracted colors
3. All new videos use consistent brand colors

### 3. Pace Matching

**User:** "Make it fast-paced like [reference]"

**Process:**
1. Analyze reference â†’ Scene changes every 3 seconds
2. Story Agent creates scenes with 3-second duration
3. Result: Matching energy and pace

### 4. Template Recreation

**User:** "Recreate this video structure"

**Process:**
1. Analyze template â†’ Scene structure, timing
2. Asset Agent maps: Scene 1 (0-5s), Scene 2 (5-13s), etc.
3. Story Agent fills scenes with new content
4. Result: Same structure, different content

## Integration with Existing System

### Gateway Workflow

```typescript
// When reference video is provided
if (input.referenceVideo) {
  // Step 1: Analyze the reference
  const analysis = await services.videoAnalyzer.analyze(input.referenceVideo);
  
  // Step 2: Route to Asset Agent with analysis
  const assetAgent = new AssetAgent();
  const assetAnalysis = await assetAgent.process({
    type: 'reference-video',
    analysis,
    prompt: input.prompt
  });
  
  // Step 3: Story Agent creates matching plan
  const storyAgent = new StoryAgent();
  const videoPlan = await storyAgent.process({
    prompt: input.prompt,
    styleReference: assetAnalysis,
    colors: analysis.colors,
    pacing: analysis.sceneChanges
  });
  
  return videoPlan;
}
```

### Service Implementation

```typescript
class VideoAnalyzerService implements Service {
  name = 'videoAnalyzer';
  
  async execute(input: { 
    videoBase64?: string; 
    videoUrl?: string;
    videoName?: string;
  }, context: WorkflowContext) {
    // Call Supabase edge function
    const response = await fetch(`${SUPABASE_URL}/functions/v1/analyze-video`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${SUPABASE_ANON_KEY}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        videoBase64: input.videoBase64,
        videoUrl: input.videoUrl,
        videoName: input.videoName,
        frameCount: 5
      })
    });
    
    const { pattern, metadata } = await response.json();
    return { pattern, metadata };
  }
}
```

## Benefits

### For Users
- **Upload reference videos** to match style
- **Consistent branding** via color extraction
- **Professional pacing** from template analysis
- **No manual color picking** - extracted automatically

### For AI System
- **Real data** instead of guessing
- **Precise timing** for scene matching
- **Actual colors** from video frames
- **Audio awareness** for beat-synced content

### Cost & Performance
- **100% FREE** - No API costs ever
- **Fast** - 5-10 second analysis
- **No limits** - Unlimited analyses
- **No signup** - Works immediately

## FFmpeg Features Used

### Frame Extraction
```bash
ffmpeg -i input.mp4 -vf "select='not(mod(n,30))'" -frames:v 5 frame_%03d.jpg
```
Extracts frames at intervals for color analysis

### Scene Detection
```bash
ffmpeg -i input.mp4 -filter:v "select='gt(scene,0.3)',showinfo" -f null -
```
Detects scene changes with configurable threshold (0.3 = 30% change)

### Audio Analysis
```bash
ffmpeg -i input.mp4 -af "volumedetect" -f null -
```
Extracts volume levels (mean/max in dB)

### Color Extraction
- Samples pixels from extracted frames
- Clusters similar colors
- Returns dominant palette
- Real colors, not guessed!

## Error Handling

```typescript
try {
  const analysis = await analyzeVideo(videoFile);
  // Use analysis
} catch (error) {
  if (error.message.includes('unsupported format')) {
    // Fallback: Use manual color input
    console.log('Video format not supported, using default colors');
  } else if (error.message.includes('too large')) {
    // Video too large (>50MB limit)
    console.log('Video too large, please use YouTube URL instead');
  } else {
    // Other error
    console.error('Analysis failed:', error);
  }
}
```

## Future Enhancements

Possible additions:
- Object detection in frames
- Text extraction (OCR)
- Motion analysis
- Face detection
- Brand logo detection
- Automatic captioning

All possible with FFmpeg + additional processing!

---

**Bottom line: Your AI agents can now "see" reference videos and extract real visual patterns to create matching content!** ðŸŽ¬
